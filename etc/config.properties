# target database where the data will sync into.
target.url = jdbc:postgresql://127.0.0.1:5432/postgres
target.user = postgres
target.passwd = 123456

# where the sync status write into, same as target by default.
# bookkeeping.url = jdbc:postgresql://127.0.0.1:5432/postgres
# bookkeeping.user = postgres
# bookkeeping.passwd = 123456

# interval of writing sync status into database in milliseconds.
bookkeeping.interval = 10000
# table name used to record sync status.
bookkeeping.table_name = bookkeeping

# data source name list, separated by comma.
data_source = mysql1, mysql2

# data source "mysql1" type, currently only support "maxwell"
mysql1.type = maxwell
# kafka server which maxwell write binlog into.
mysql1.kafka.server = 127.0.0.1:9092
# kafka topic which maxwell write binlog into.
mysql1.kafka.topic = topic_name1

# data source "mysql2" type, currently only support "maxwell"
mysql2.type = maxwell
# kafka server which maxwell write binlog into.
mysql2.kafka.server = 127.0.0.1:9092
# kafka topic which maxwell write binlog into.
mysql2.kafka.topic = topic_name2

# application performance monitor report type: "none", "console", "jmx"
metrics.reporter=console
# interval of console APM reporter.
metrics.reporter.console.interval = 10

# JDBC connection pool size of target database.
loader.conn_pool.size = 10
# queue size of task for each table which is waiting for load.
loader.task_queue.size = 2

# number of threads used to transform data source record into target format.
transform.thread_pool.size = 10

# number of threads used to generate load tasks.
merge.thread_pool.size = 10
# interval of generating a load task in milliseconds.
merge.interval = 10000
# max tuple size for a load task
merge.batch.size = 50000


